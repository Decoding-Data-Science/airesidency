{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Decoding-Data-Science/airesidency/blob/main/ragmc/Yet_another_copy_of_PineconeIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714eb664",
      "metadata": {
        "id": "714eb664"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/PineconeIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
      "metadata": {
        "id": "307804a3-c02b-4a57-ac0d-172c30ddc851"
      },
      "source": [
        "# Pinecone Vector Store"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36be66bf",
      "metadata": {
        "id": "36be66bf"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddff1e4",
      "metadata": {
        "id": "9ddff1e4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install llama-index llama-index-vector-stores-pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3KbgDaxfBa9"
      },
      "id": "h3KbgDaxfBa9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d48af8e1",
      "metadata": {
        "id": "d48af8e1"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
      "metadata": {
        "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396"
      },
      "source": [
        "#### Creating a Pinecone Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0ce3143d-198c-4dd2-8e5a-c5cdf94f017a",
      "metadata": {
        "id": "0ce3143d-198c-4dd2-8e5a-c5cdf94f017a"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the OpenAI API key from Google Colab secrets\n",
        "openai.api_key = userdata.get('openai')\n",
        "\n",
        "if openai.api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ],
      "metadata": {
        "id": "3mf6ed5pBFwj"
      },
      "id": "3mf6ed5pBFwj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4ad14111-0bbb-4c62-906d-6d6253e0cdee",
      "metadata": {
        "id": "4ad14111-0bbb-4c62-906d-6d6253e0cdee"
      },
      "outputs": [],
      "source": [
        "#PUT Tyour aopi key\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "api_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "if api_key:\n",
        "    os.environ[\"PINECONE_API_KEY\"] = api_key\n",
        "\n",
        "\n",
        "pc = Pinecone(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "233a080f",
      "metadata": {
        "id": "233a080f"
      },
      "outputs": [],
      "source": [
        "#delete if needed\n",
        "pc.delete_index(\"quickstart\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c90087-bdd9-4ca4-b06b-2af883559f88",
      "metadata": {
        "id": "c2c90087-bdd9-4ca4-b06b-2af883559f88"
      },
      "outputs": [],
      "source": [
        "# dimensions are for text-embedding-ada-002\n",
        "\n",
        "pc.create_index(\n",
        "    name=\"quickstart\",\n",
        "    dimension=1536,\n",
        "    metric=\"euclidean\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6",
      "metadata": {
        "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6"
      },
      "outputs": [],
      "source": [
        "pinecone_index = pc.Index(\"quickstart\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
      "metadata": {
        "id": "8ee4473a-094f-4d0a-a825-e1213db07240"
      },
      "source": [
        "#### Load documents, build the PineconeVectorStore and VectorStoreIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2bcc07",
      "metadata": {
        "id": "0a2bcc07"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d782f76",
      "metadata": {
        "id": "7d782f76"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5104674e",
      "metadata": {
        "id": "5104674e"
      },
      "outputs": [],
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
      "metadata": {
        "id": "68cbd239-880e-41a3-98d8-dbb3fab55431"
      },
      "outputs": [],
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "Jv678Qg8x1HG"
      },
      "id": "Jv678Qg8x1HG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba1558b3",
      "metadata": {
        "id": "ba1558b3"
      },
      "outputs": [],
      "source": [
        "# initialize without metadata filter\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04304299-fc3e-40a0-8600-f50c3292767e",
      "metadata": {
        "id": "04304299-fc3e-40a0-8600-f50c3292767e"
      },
      "source": [
        "#### Query Index\n",
        "\n",
        "May take a minute or so for the index to be ready!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35369eda",
      "metadata": {
        "id": "35369eda"
      },
      "outputs": [],
      "source": [
        "# set Logging to DEBUG for more detailed outputs\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"what is this document about\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
      "metadata": {
        "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
        "outputId": "dc77b12e-c790-4870-8c9b-90e0e00a364d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>The document is about the author's reflections on his experiences with writing essays, choosing what to work on, the evolution of computers, his time in Florence, the challenges of dealing with responses to his essays, the evolution of Y Combinator, and the impact of customs on various fields affected by rapid change.</b>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "EgDEgB0_cOYo"
      },
      "id": "EgDEgB0_cOYo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "%pip install -q llama-index llama-index-vector-stores-pinecone gradio\n",
        "\n",
        "# --- Imports ---\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import gradio as gr\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
        "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
        "\n",
        "# --- Logging ---\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "# --- Set API Keys ---\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_3hG9JF_HUuVnMGYDVoeTZctGjvTJRASUnQQjnDVFNUMX2ntkdBsfhLbbYxapdLzTaedRaK\"\n",
        "\n",
        "\n",
        "api_key = os.environ[\"PINECONE_API_KEY\"]\n",
        "\n",
        "\n",
        "# --- Initialize Pinecone ---\n",
        "pc = Pinecone(api_key=api_key)\n",
        "index_name = \"quickstart\"\n",
        "dimension = 1536\n",
        "\n",
        "# Delete index if exists (optional)\n",
        "if index_name in [idx['name'] for idx in pc.list_indexes()]:\n",
        "    pc.delete_index(index_name)\n",
        "\n",
        "# Create Pinecone index\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=dimension,\n",
        "    metric=\"euclidean\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "pinecone_index = pc.Index(index_name)\n",
        "\n",
        "# --- Load Data ---\n",
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget -q 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'\n",
        "\n",
        "#change directory\n",
        "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
        "\n",
        "# --- Create Index ---\n",
        "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
        "\n",
        "# --- Query Engine ---\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# --- Gradio App ---\n",
        "def query_doc(prompt):\n",
        "    try:\n",
        "        response = query_engine.query(prompt)\n",
        "        return str(response)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "gr.Interface(\n",
        "    fn=query_doc,\n",
        "    inputs=gr.Textbox(label=\"Ask a question about the document\"),\n",
        "    outputs=gr.Textbox(label=\"Answer\"),\n",
        "    title=\"Paul Graham Document QA (LlamaIndex + Pinecone)\",\n",
        "    description=\"Ask questions based on the indexed Paul Graham essay. Powered by LlamaIndex & Pinecone.\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "id": "4B5eSIxPcNEI"
      },
      "id": "4B5eSIxPcNEI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "op8voXD_DENK"
      },
      "id": "op8voXD_DENK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}