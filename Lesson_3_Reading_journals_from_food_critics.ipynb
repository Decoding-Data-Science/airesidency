{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Decoding-Data-Science/airesidency/blob/main/Lesson_3_Reading_journals_from_food_critics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbz2dQO8wU0K"
      },
      "source": [
        "# Lesson 3: Reading journals from food critics\n",
        "\n",
        "In this lesson, you'll use AI to decide whether the contents of a file are about food and restaurants.\n",
        "\n",
        "Text data like emails, journal entries, and social media posts often have no predefined structure. Additionally, each person writes in their own style: some use bullet points, while others prefer long paragraphs. For this reason, text data is known as **unstructured data**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZQoeoMcwU0M"
      },
      "source": [
        "Let's start by loading some helper functions to use in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "2H-91mxbwU0N"
      },
      "outputs": [],
      "source": [
        "from helper_functions import get_llm_response, print_llm_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpWDlt7wU0N"
      },
      "source": [
        "## Working with text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMF3R2GnwU0O"
      },
      "source": [
        "You'll take look at journal entries in the working directory. The journals are stored as plain text files with extension `.txt'.\n",
        "\n",
        "Start by opening and reading the Cape Town journal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "height": 64,
        "id": "TI3kNaddwU0O"
      },
      "outputs": [],
      "source": [
        "f = open(\"cape_town.txt\", \"r\")\n",
        "journal_cape_town = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNw-Uol4wU0O"
      },
      "source": [
        "Print the contents of the journal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZrhyeERwU0O",
        "outputId": "8f610eff-2252-4f92-f715-c8dba921987a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My first destination was The Test Kitchen, a restaurant that has earned its place among the world's best. Situated in the trendy Woodstock area, this dining spot is celebrated for its innovative dishes. I was particularly taken by their signature dish, the \"Pickled Fish Tacos.\" The tangy, flavorful fish wrapped in a soft taco, paired with a zesty salsa, was a delightful start to my culinary adventure. The industrial-chic ambiance added a modern edge to the dining experience.\n",
            "\n",
            "Next, I made my way to La Colombe, perched on the slopes of Constantia. Known for its refined and artistic approach to cuisine, La Colombe's \"Tuna La Colombe\" is a must-try. This dish features perfectly seared tuna, complemented by a delicate ponzu dressing and bursts of citrus. The presentation was as exquisite as the flavors, making it a memorable highlight of the day.\n",
            "\n",
            "At the bustling V&A Waterfront, I visited Harbour House for some of the freshest seafood in town. The \"Grilled Kingklip\" was a revelation. The succulent, flaky fish, grilled to perfection and served with a side of roasted vegetables, highlighted the ocean's bounty. The stunning views of the harbor added to the meal's appeal.\n",
            "\n",
            "Finally, my journey concluded at The Pot Luck Club, another gem in Woodstock. This trendy spot is known for its small plates, perfect for sharing. The standout dish was the \"Beef Tataki.\" Thinly sliced, seared beef with a tangy soy dressing and a hint of wasabi provided a burst of umami and heat. The eclectic, artistic vibe of the restaurant made for a fitting end to my culinary tour.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_cape_town)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXfqG1DZwU0O"
      },
      "source": [
        "As you can see, the file is about restaurants and food.\n",
        "\n",
        "Next, open the Tokyo journal entry file and read its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "height": 64,
        "id": "2zlK0zqnwU0l"
      },
      "outputs": [],
      "source": [
        "f = open(\"tokyo.txt\", \"r\")\n",
        "journal_tokyo = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf5CAzDCwU0m"
      },
      "source": [
        "Print the contents of the journal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GcuZymbwU0m",
        "outputId": "203cad7c-ff97-46d4-848d-3a167a2c8a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokyo's culinary landscape is nothing short of extraordinary. Each spot offers a unique taste of the city's diverse food culture. Here's a quick guide to some must-try places and dishes.\n",
            "\n",
            "    Sukiyabashi Jiro\n",
            "        Location: Ginza\n",
            "        Dish: Omakase sushi\n",
            "        Highlight: Impeccably crafted sushi made by the legendary Jiro Ono. Each piece is a masterclass in balance and flavor.\n",
            "\n",
            "    Ichiran Ramen\n",
            "        Location: Shibuya\n",
            "        Dish: Tonkotsu ramen\n",
            "        Highlight: A personal ramen booth for focused, uninterrupted enjoyment. Rich, creamy broth with perfectly cooked noodles.\n",
            "\n",
            "    Tsukiji Outer Market\n",
            "        Location: Tsukiji\n",
            "        Dish: Fresh sashimi and street food\n",
            "        Highlight: Vibrant market atmosphere. Indulge in ultra-fresh sashimi, grilled seafood, and other Japanese street food delights.\n",
            "\n",
            "    Narisawa\n",
            "        Location: Minato\n",
            "        Dish: Innovative tasting menu\n",
            "        Highlight: A fusion of French and Japanese techniques. Creative dishes with an emphasis on sustainability and local ingredients.\n",
            "\n",
            "    Ginza Kojyu\n",
            "        Location: Ginza\n",
            "        Dish: Kaiseki (traditional multi-course meal)\n",
            "        Highlight: Exquisite presentation and meticulous preparation. A journey through seasonal Japanese flavors.\n",
            "\n",
            "    Akasaka Kikunoi\n",
            "        Location: Akasaka\n",
            "        Dish: Kaiseki\n",
            "        Highlight: Elegant and serene setting. Seasonal ingredients transformed into artful, delicious courses.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_tokyo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aldHHub6wU0m"
      },
      "source": [
        "This entry is also about restaurants and food - but notice how different the format of the journal is from the Cape Town example!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxDeMQlowU0m"
      },
      "source": [
        "## Determining if text files are relevant using LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBJmTPMNwU0m"
      },
      "source": [
        "In this section, you'll write a prompt that instructs an LLM to determine whether a file content is about food and restaurants or some other topic.\n",
        "\n",
        "Define the prompt and include the Tokyo journal entry as the input data to check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "height": 98,
        "id": "b_HGtzKjwU0n"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\":\n",
        "the journal describes restaurants and their specialties.\n",
        "\n",
        "Journal:\n",
        "{journal_tokyo}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbV4HxvDwU0n"
      },
      "source": [
        "Print the LLM response to see if the file is relevant for our purpose or not:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the OpenAI library\n",
        "!pip install openai==0.28\n",
        "\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the OpenAI API key from Google Colab secrets\n",
        "openai.api_key = userdata.get('openai')\n",
        "\n",
        "def print_llm_response(prompt: str, max_tokens: int = 1000):\n",
        "    \"\"\"\n",
        "    Fetch and print an LLM response using the OpenAI library.\n",
        "\n",
        "    Parameters:\n",
        "        prompt (str): The input prompt to query the LLM.\n",
        "        max_tokens (int): Maximum number of tokens to include in the response.\n",
        "    \"\"\"\n",
        "    # Use the updated `ChatCompletion` API\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",  # Specify the appropriate model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    # Extract and print the response text\n",
        "    response_text = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    print(f\"Response:\\n{'-'*40}\\n{response_text}\\n{'-'*40}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv4FE8Hfxd9y",
        "outputId": "951dff40-cd91-45d5-ab65-8e6ad81fc046"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "# Retrieve the OpenAI API key from Google Colab secrets\n",
        "openai.api_key = userdata.get('openai')\n",
        "\n",
        "def get_llm_response(prompt):\n",
        "    \"\"\"This function takes a prompt as input and queries OpenAI's GPT model for a response.\"\"\"\n",
        "    # Send the request to OpenAI API\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful but concise AI assistant.\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        temperature=0.0,\n",
        "    )\n",
        "    response = completion.choices[0].message.content\n",
        "    return response"
      ],
      "metadata": {
        "id": "2cVXaMq9zEei"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ6fLCa_wU0o",
        "outputId": "0cf4242d-8431-4883-b0be-d69d0b05b483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "----------------------------------------\n",
            "Relevant\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print_llm_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "z3UNVa7PyP8q",
        "outputId": "ef791162-7a59-4df7-cb36-27bd02fe87b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Respond with \"Relevant\" or \"Not relevant\": \\nthe journal describes restaurants and their specialties. \\n\\nJournal:\\nTokyo\\'s culinary landscape is nothing short of extraordinary. Each spot offers a unique taste of the city\\'s diverse food culture. Here\\'s a quick guide to some must-try places and dishes.\\n\\n    Sukiyabashi Jiro\\n        Location: Ginza\\n        Dish: Omakase sushi\\n        Highlight: Impeccably crafted sushi made by the legendary Jiro Ono. Each piece is a masterclass in balance and flavor.\\n\\n    Ichiran Ramen\\n        Location: Shibuya\\n        Dish: Tonkotsu ramen\\n        Highlight: A personal ramen booth for focused, uninterrupted enjoyment. Rich, creamy broth with perfectly cooked noodles.\\n\\n    Tsukiji Outer Market\\n        Location: Tsukiji\\n        Dish: Fresh sashimi and street food\\n        Highlight: Vibrant market atmosphere. Indulge in ultra-fresh sashimi, grilled seafood, and other Japanese street food delights.\\n\\n    Narisawa\\n        Location: Minato\\n        Dish: Innovative tasting menu\\n        Highlight: A fusion of French and Japanese techniques. Creative dishes with an emphasis on sustainability and local ingredients.\\n\\n    Ginza Kojyu\\n        Location: Ginza\\n        Dish: Kaiseki (traditional multi-course meal)\\n        Highlight: Exquisite presentation and meticulous preparation. A journey through seasonal Japanese flavors.\\n\\n    Akasaka Kikunoi\\n        Location: Akasaka\\n        Dish: Kaiseki\\n        Highlight: Elegant and serene setting. Seasonal ingredients transformed into artful, delicious courses.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJM7XC_UwU0o"
      },
      "source": [
        "## Checking all files using a `for` loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaSARshHwU0o"
      },
      "source": [
        "Using Python and an LLM together allows you to quickly iterate over multiple files and check the relevance of the content for your tasks.\n",
        "\n",
        "Start by creating a list of all the files you want to check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "height": 47,
        "id": "Lr_HU-aEwU0o"
      },
      "outputs": [],
      "source": [
        "# List of the journal files\n",
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWnT_gMIwU0o"
      },
      "source": [
        "Next, use a `for` loop to open each file and have an LLM check if the content from that file is relevant to food and restaurants.\n",
        "* *If you need a refresher on `for` loops, please revisit Course 2!*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaPxrWWtydOC",
        "outputId": "5a04db4c-0f23-4ff1-b2a5-99dc15eed8aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cape_town.txt',\n",
              " 'madrid.txt',\n",
              " 'rio_de_janeiro.txt',\n",
              " 'sydney.txt',\n",
              " 'tokyo.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "height": 268,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTSfeAAowU0o",
        "outputId": "da2f50ec-3158-4a92-c3fe-63d777ff8929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cape_town.txt ------------> Relevant\n",
            "madrid.txt ------------> Not relevant\n",
            "rio_de_janeiro.txt ------------> Relevant\n",
            "sydney.txt ------------> Relevant\n",
            "tokyo.txt ------------> Relevant\n"
          ]
        }
      ],
      "source": [
        "for file in files:\n",
        "    # Read journal file for the city\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # Create prompt\n",
        "    prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\":\n",
        "    the journal describes restaurants and their specialties.\n",
        "\n",
        "    Journal:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # Use LLM to determine if the journal entry is useful\n",
        "    print(f\"{file} ------------> {get_llm_response(prompt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNBtudCbwU0o"
      },
      "source": [
        "It seems that the Madrid journal entry is not relevant. Let's print its contents to see why the LLM flagged it as \"not relevant\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "height": 81,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWUzWgYdwU0o",
        "outputId": "e471db93-28b8-47ab-a14e-a1562b6e6a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Madrid, as Spain's capital and largest city, is a key player in the nation's economy. Historically centered around its administrative functions, Madrid has evolved into a major financial hub, hosting the Madrid Stock Exchange and the headquarters of numerous national and international companies.\n",
            "\n",
            "The service sector, especially tourism, is vital to Madrid's economy. Millions of tourists visit annually, attracted by the city's cultural landmarks, museums, and vibrant nightlife. Additionally, trade fairs and conferences at venues like IFEMA (Feria de Madrid) bring significant business traffic.\n",
            "\n",
            "Innovation and technology are also growing sectors in Madrid. The city boasts a thriving startup ecosystem and hosts many tech companies, supported by a highly educated workforce from its universities and research institutions. This has spurred growth in IT, biotechnology, and renewable energy.\n",
            "\n",
            "Madrid's well-developed transportation network, including a comprehensive metro system, high-speed rail, and Adolfo Suárez Madrid-Barajas Airport, enhances its role as a logistical and commercial hub. This connectivity supports trade and commerce, both within Spain and internationally, solidifying Madrid's status as a leading economic center in Europe.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Here you can check the content from any journal entry\n",
        "f = open(\"madrid.txt\", \"r\")\n",
        "print(f.read())\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzAsYxgzwU0o"
      },
      "source": [
        "The Madrid journal entry doesn't contain information about restaurants to try. Instead, it is a description of the economy of the city."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1fa1kuSwU0p"
      },
      "source": [
        "<p style=\"background-color:#F5C780; padding:15px\"> 🤖 <b>Use the Chatbot</b>:\n",
        "    <br><br>\n",
        "    I am using AI to determine whether different texts are \"relevant\" or \"not relevant\" using an LLM. Does this task have a specific name in AI?\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcW_XNMywU0p"
      },
      "source": [
        "## Extra practice\n",
        "\n",
        "Experiment with different prompts to check whether files are of interest to you or not. Below is the example suggested in the video - try running it first. Then, try each exercise.\n",
        "\n",
        "### Exercise 1\n",
        "\n",
        "Change the prompt to classify the text for different topics, for example \"mentions a dessert\" or \"describes the restaurant design.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 319,
        "id": "gGsIJR-KwU0p"
      },
      "outputs": [],
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # Read journal file for the city\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # TRY CHANGING THIS PROMPT TO ASK DIFFERENT QUESTIONS\n",
        "    prompt = f\"\"\"Respond with \"Yes\" or \"No\":\n",
        "    the journal describes restaurants and food dishes.\n",
        "\n",
        "    Journal:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # Use LLM to determine if the journal entry is useful\n",
        "    print(f\"{file} -> {get_llm_response(prompt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogv79foMwU0p"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Using the same code below, change the prompt to classify into more than two categories.\n",
        "\n",
        "**Example:**\n",
        "- mentions a **vegetarian** dish\n",
        "- mentions a **vegan** dish\n",
        "- mentions both\n",
        "- mentions neither"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 319,
        "id": "gGa91AOQwU0p"
      },
      "outputs": [],
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # Read journal file for the city\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # TRY CHANGING THIS PROMPT TO ASK DIFFERENT QUESTIONS\n",
        "    prompt = f\"\"\"Respond with \"Yes\" or \"No\":\n",
        "    the journal describes restaurants and food dishes.\n",
        "\n",
        "    Journal:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # Use LLM to determine if the journal entry is useful\n",
        "    print(f\"{file} -> {get_llm_response(prompt)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}